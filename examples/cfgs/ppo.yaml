defaults:
  action_size: 4
  num_timesteps: 1_000_000_000
  num_evals: 400
  reward_scaling: 10
  episode_length: 1000
  normalize_observations: True
  action_repeat: 1
  unroll_length: 20
  num_minibatches: 32
  num_updates_per_batch: 4
  discounting: 0.99
  _learning_rate: 0.0003
  entropy_cost: 0
  num_envs: 2048
  batch_size: 1024

drone_target_dyn:
  action_size: 4
  num_timesteps: 1_000_000_000
  num_evals: 400
  reward_scaling: 10
  episode_length: 1000
  normalize_observations: True
  action_repeat: 1
  unroll_length: 20
  num_minibatches: 32
  num_updates_per_batch: 4
  discounting: 0.99
  _learning_rate: 0.0003
  entropy_cost: 0
  num_envs: 2048
  batch_size: 1024

